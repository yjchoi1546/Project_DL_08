{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c4a59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM, AblationCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "import torchvision.models as models\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F # 소프트맥스 활성화를 위해 추가\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6d93c2",
   "metadata": {},
   "source": [
    "# ResNet50 모델 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44856725",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = models.resnet50(pretrained=False)\n",
    "print(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839888d0",
   "metadata": {},
   "source": [
    "### 가중치 학습된 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12e3e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.load(\"model/Best_ResNet50_model.pth\", map_location=torch.device('cpu'))\n",
    "model = models.resnet50(pretrained=False)\n",
    "model.fc = nn.Linear(in_features=2048, out_features=13, bias=True)\n",
    "model.load_state_dict(weights)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b819da11",
   "metadata": {},
   "source": [
    "### 풀 데이터 셋 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9353ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_datasets = ImageFolder(root='data/Dataset_project4')\n",
    "class_names = full_datasets.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc863b2",
   "metadata": {},
   "source": [
    "## 데이터 전처리 코드 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d798f216",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "    # transforms.Resize((512, 512)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.2),\n",
    "    # 무작위 원근 왜곡 추가\n",
    "    transforms.RandomPerspective(distortion_scale=0.5, p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transforms_test = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61204ab5",
   "metadata": {},
   "source": [
    "#### 데이터 학습시켰을때랑 똑같은 random 값 줘서 쪼개기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba88a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 데이터 크기와 target 저장 \n",
    "total_size = len(full_datasets)\n",
    "targets = full_datasets.targets\n",
    "\n",
    "train_indices, test_indices = train_test_split(\n",
    "    np.arange(total_size),\n",
    "    test_size=0.2,\n",
    "    stratify=targets,\n",
    "    random_state=42   \n",
    ")\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(full_datasets, train_indices)\n",
    "test_dataset = torch.utils.data.Subset(full_datasets, test_indices)\n",
    "\n",
    "print(\"\\n데이터셋 분할 완료.\")\n",
    "print(f\"총 데이터 수: {total_size}\")\n",
    "print(f\"학습용 데이터 수: {len(train_dataset)}\")\n",
    "print(f\"검증용 데이터 수: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d92ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.dataset.transform = transforms_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c568a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = test_dataset[0]\n",
    "\n",
    "print(img.shape)\n",
    "print(label)\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879a239a",
   "metadata": {},
   "source": [
    "#### 그래드 캠에 쓸 타겟 레이어 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c206e381",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layer = model.layer4[-1].conv3\n",
    "target_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b85621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = GradCAM(model=model, target_layers=[target_layer])\n",
    "cam.batch_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c38a2c",
   "metadata": {},
   "source": [
    "#### 원본 이미지 제대로 보기위해 역정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f416c2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet 표준 정규화 값 (모델 학습 시 사용한 값과 일치해야 함)\n",
    "# 만약 다른 값으로 정규화했다면 이 값을 변경해야 합니다.\n",
    "NORM_MEAN = [0.485, 0.456, 0.406]\n",
    "NORM_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "def denormalize_image(tensor_image, mean=NORM_MEAN, std=NORM_STD):\n",
    "    \"\"\"\n",
    "    정규화된 이미지 텐서를 역정규화하여 0-1 범위의 NumPy 배열로 변환합니다.\n",
    "    \"\"\"\n",
    "    for t, m, s in zip(tensor_image, mean, std):\n",
    "        t.mul_(s).add_(m) # t = t * s + m\n",
    "    \n",
    "    # 텐서를 NumPy 배열로 변환하고 채널 순서를 (H, W, C)로 변경\n",
    "    np_image = tensor_image.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    # 픽셀 값을 0-1 범위로 클리핑하여 유효한 이미지 범위 유지\n",
    "    np_image = np.clip(np_image, 0, 1)\n",
    "    \n",
    "    return np_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444493f9",
   "metadata": {},
   "source": [
    "### 갈색 유리병(Label4) 특징맵이 잘 찾는지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78e67cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨 4인 이미지를 저장할 리스트\n",
    "label_4_images_info = []\n",
    "count = 0\n",
    "\n",
    "# test_dataset에서 라벨이 4인 이미지 최대 100개를 찾습니다.\n",
    "for i, (img, label) in enumerate(test_dataset):\n",
    "    if label == 4:\n",
    "        label_4_images_info.append((img, label, i)) # (이미지 텐서, 실제 라벨, 원본 인덱스)\n",
    "        count += 1\n",
    "        if count >= 100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adbd659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 평가 모드로 설정\n",
    "model.eval()\n",
    "\n",
    "if not label_4_images_info:\n",
    "    print(\"라벨이 4인 이미지를 찾을 수 없습니다.\")\n",
    "else:\n",
    "    print(f\"라벨이 4인 이미지 {len(label_4_images_info)}개를 찾았습니다. 시각화를 시작합니다.\")\n",
    "\n",
    "    # 각 이미지에 대해 Grad-CAM과 예측을 시각화\n",
    "    for k, (original_img_tensor, actual_label, original_idx) in enumerate(label_4_images_info):\n",
    "        # Grad-CAM을 적용하기 위해 이미지 차원을 확장합니다 (배치 크기 1).\n",
    "        input_tensor = original_img_tensor.unsqueeze(0)\n",
    "        \n",
    "        # 모델 예측 수행\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            probabilities = F.softmax(output, dim=1) # 소프트맥스로 확률 변환\n",
    "            predicted_prob, predicted_label = torch.max(probabilities, 1) # 가장 높은 확률과 해당 라벨\n",
    "        \n",
    "        # Grad-CAM 인스턴스에 적용할 타겟을 지정합니다. 여기서는 라벨 4에 대한 CAM을 계산합니다.\n",
    "        # 실제 예측된 라벨에 대한 CAM을 보고 싶다면 targets = [ClassifierOutputTarget(predicted_label.item())] 로 변경\n",
    "        targets = [ClassifierOutputTarget(4)] \n",
    "        \n",
    "        # Grad-CAM을 계산합니다.\n",
    "        grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "        \n",
    "        # 결과를 이미지에 덧입히기 위해 CAM 값을 첫 번째 차원을 제거합니다.\n",
    "        grayscale_cam = grayscale_cam[0, :]\n",
    "\n",
    "        # 원본 이미지 텐서를 역정규화하고 NumPy 배열로 변환\n",
    "        denormalized_rgb_img = denormalize_image(original_img_tensor.cpu())\n",
    "        \n",
    "        # CAM 히트맵을 역정규화된 원본 이미지에 덧씌웁니다.\n",
    "        visualization = show_cam_on_image(denormalized_rgb_img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "        # 결과 시각화\n",
    "        plt.figure(figsize=(8, 4)) # 이미지 크기 조정\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(denormalized_rgb_img)\n",
    "        plt.title(f\"Original Image (Actual: {actual_label})\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(visualization)\n",
    "        plt.title(f\"Grad-CAM (Predicted: {predicted_label.item()}, Prob: {predicted_prob.item():.2f})\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.suptitle(f\"Image {k+1}/{len(label_4_images_info)} (Dataset Index: {original_idx})\")\n",
    "        plt.show()\n",
    "        \n",
    "        # 3장만 우선 보고 싶다면, 여기서 break\n",
    "        if k >= 100: \n",
    "           break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc76bff",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-aug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
