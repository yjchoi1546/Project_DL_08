{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eedff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM, AblationCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "import torchvision.models as models\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F # 소프트맥스 활성화를 위해 추가\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f29dbb",
   "metadata": {},
   "source": [
    "### 가중치 학습된 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da073296",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\project_aug\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\project_aug\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (8): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=True)\n",
       "    (1): Linear(in_features=1280, out_features=13, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.load(\"model/lr1e4_512best_efficientB0_model_pretrained_weights827.pth\", map_location=torch.device('cpu'))\n",
    "model = models.efficientnet_b0(pretrained=False)\n",
    "model.classifier[1] = nn.Linear(in_features=1280, out_features=13, bias=True)\n",
    "model.load_state_dict(weights)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deba1e77",
   "metadata": {},
   "source": [
    "### 풀 데이터 셋 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d28fbb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['금속캔알루미늄캔',\n",
       " '금속캔철캔',\n",
       " '비닐',\n",
       " '스티로폼',\n",
       " '유리병갈색',\n",
       " '유리병녹색',\n",
       " '유리병투명',\n",
       " '종이',\n",
       " '페트병무색단일',\n",
       " '페트병유색단일',\n",
       " '플라스틱PE',\n",
       " '플라스틱PP',\n",
       " '플라스틱PS']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_datasets = ImageFolder(root='data/Dataset_project4')\n",
    "class_names = full_datasets.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bbdaeb",
   "metadata": {},
   "source": [
    "#### 데이터 전처리 코드 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d476f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "    #transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transforms_test = transforms.Compose([\n",
    "    #transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b73cd2",
   "metadata": {},
   "source": [
    "#### 데이터 학습시켰을때랑 똑같은 random 값 줘서 쪼개기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa0fffc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "데이터셋 분할 완료.\n",
      "총 데이터 수: 69898\n",
      "학습용 데이터 수: 55918\n",
      "검증용 데이터 수: 13980\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 데이터 크기와 target 저장 \n",
    "total_size = len(full_datasets)\n",
    "targets = full_datasets.targets\n",
    "\n",
    "train_indices, test_indices = train_test_split(\n",
    "    np.arange(total_size),\n",
    "    test_size=0.2,\n",
    "    stratify=targets,\n",
    "    random_state=42   \n",
    ")\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(full_datasets, train_indices)\n",
    "test_dataset = torch.utils.data.Subset(full_datasets, test_indices)\n",
    "\n",
    "print(\"\\n데이터셋 분할 완료.\")\n",
    "print(f\"총 데이터 수: {total_size}\")\n",
    "print(f\"학습용 데이터 수: {len(train_dataset)}\")\n",
    "print(f\"검증용 데이터 수: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ac4f76",
   "metadata": {},
   "source": [
    "전처리 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9923fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.dataset.transform = transforms_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12b1e7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 512, 512])\n",
      "0\n",
      "13980\n"
     ]
    }
   ],
   "source": [
    "img, label = test_dataset[0]\n",
    "\n",
    "print(img.shape)\n",
    "print(label)\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04f90ce",
   "metadata": {},
   "source": [
    "#### 그래드 캠에 쓸 타겟 레이어 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddcfafa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_layer = model.features[-1][0]\n",
    "target_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10493496",
   "metadata": {},
   "source": [
    "#### 그래드캠 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90098e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = GradCAM(model=model, target_layers=[target_layer])\n",
    "cam.batch_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81df4929",
   "metadata": {},
   "source": [
    "#### 원본 이미지 제대로 보기위해 역정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a844c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet 표준 정규화 값 (모델 학습 시 사용한 값과 일치해야 함)\n",
    "# 만약 다른 값으로 정규화했다면 이 값을 변경해야 합니다.\n",
    "NORM_MEAN = [0.485, 0.456, 0.406]\n",
    "NORM_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "def denormalize_image(tensor_image, mean=NORM_MEAN, std=NORM_STD):\n",
    "    \"\"\"\n",
    "    정규화된 이미지 텐서를 역정규화하여 0-1 범위의 NumPy 배열로 변환합니다.\n",
    "    \"\"\"\n",
    "    for t, m, s in zip(tensor_image, mean, std):\n",
    "        t.mul_(s).add_(m) # t = t * s + m\n",
    "    \n",
    "    # 텐서를 NumPy 배열로 변환하고 채널 순서를 (H, W, C)로 변경\n",
    "    np_image = tensor_image.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    # 픽셀 값을 0-1 범위로 클리핑하여 유효한 이미지 범위 유지\n",
    "    np_image = np.clip(np_image, 0, 1)\n",
    "    \n",
    "    return np_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be9dcaa",
   "metadata": {},
   "source": [
    "### 갈색 유리병 특징맵이 잘 찾는지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ee2655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨 4인 이미지를 저장할 리스트\n",
    "label_4_images_info = []\n",
    "count = 0\n",
    "\n",
    "# test_dataset에서 라벨이 4인 이미지 최대 100개를 찾습니다.\n",
    "for i, (img, label) in enumerate(test_dataset):\n",
    "    if label == 4:\n",
    "        label_4_images_info.append((img, label, i)) # (이미지 텐서, 실제 라벨, 원본 인덱스)\n",
    "        count += 1\n",
    "        if count >= 100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a8f497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 평가 모드로 설정\n",
    "model.eval()\n",
    "\n",
    "if not label_4_images_info:\n",
    "    print(\"라벨이 4인 이미지를 찾을 수 없습니다.\")\n",
    "else:\n",
    "    print(f\"라벨이 4인 이미지 {len(label_4_images_info)}개를 찾았습니다. 시각화를 시작합니다.\")\n",
    "\n",
    "    # 각 이미지에 대해 Grad-CAM과 예측을 시각화\n",
    "    for k, (original_img_tensor, actual_label, original_idx) in enumerate(label_4_images_info):\n",
    "        # Grad-CAM을 적용하기 위해 이미지 차원을 확장합니다 (배치 크기 1).\n",
    "        input_tensor = original_img_tensor.unsqueeze(0)\n",
    "        \n",
    "        # 모델 예측 수행\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            probabilities = F.softmax(output, dim=1) # 소프트맥스로 확률 변환\n",
    "            predicted_prob, predicted_label = torch.max(probabilities, 1) # 가장 높은 확률과 해당 라벨\n",
    "        \n",
    "        # Grad-CAM 인스턴스에 적용할 타겟을 지정합니다. 여기서는 라벨 4에 대한 CAM을 계산합니다.\n",
    "        # 실제 예측된 라벨에 대한 CAM을 보고 싶다면 targets = [ClassifierOutputTarget(predicted_label.item())] 로 변경\n",
    "        targets = [ClassifierOutputTarget(4)] \n",
    "        \n",
    "        # Grad-CAM을 계산합니다.\n",
    "        grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "        \n",
    "        # 결과를 이미지에 덧입히기 위해 CAM 값을 첫 번째 차원을 제거합니다.\n",
    "        grayscale_cam = grayscale_cam[0, :]\n",
    "\n",
    "        # 원본 이미지 텐서를 역정규화하고 NumPy 배열로 변환\n",
    "        denormalized_rgb_img = denormalize_image(original_img_tensor.cpu())\n",
    "        \n",
    "        # CAM 히트맵을 역정규화된 원본 이미지에 덧씌웁니다.\n",
    "        visualization = show_cam_on_image(denormalized_rgb_img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "        # 결과 시각화\n",
    "        plt.figure(figsize=(8, 4)) # 이미지 크기 조정\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(denormalized_rgb_img)\n",
    "        plt.title(f\"Original Image (Actual: {actual_label})\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(visualization)\n",
    "        plt.title(f\"Grad-CAM (Predicted: {predicted_label.item()}, Prob: {predicted_prob.item():.2f})\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.suptitle(f\"Image {k+1}/{len(label_4_images_info)} (Dataset Index: {original_idx})\")\n",
    "        plt.show()\n",
    "        \n",
    "        # 3장만 우선 보고 싶다면, 여기서 break\n",
    "        if k >= 100: \n",
    "           break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bf0d95",
   "metadata": {},
   "source": [
    "### 플라스틱PS 특징맵이 잘 찾는지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8a1351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨 4인 이미지를 저장할 리스트\n",
    "label_12_images_info = []\n",
    "count = 0\n",
    "\n",
    "# test_dataset에서 라벨이 4인 이미지 최대 100개를 찾습니다.\n",
    "for i, (img, label) in enumerate(test_dataset):\n",
    "    if label == 12:\n",
    "        label_12_images_info.append((img, label, i)) # (이미지 텐서, 실제 라벨, 원본 인덱스)\n",
    "        count += 1\n",
    "        if count >= 100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81874cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 평가 모드로 설정\n",
    "model.eval()\n",
    "\n",
    "if not label_12_images_info:\n",
    "    print(\"라벨이 12인 이미지를 찾을 수 없습니다.\")\n",
    "else:\n",
    "    print(f\"라벨이 12인 이미지 {len(label_12_images_info)}개를 찾았습니다. 시각화를 시작합니다.\")\n",
    "\n",
    "    # 각 이미지에 대해 Grad-CAM과 예측을 시각화\n",
    "    for k, (original_img_tensor, actual_label, original_idx) in enumerate(label_12_images_info):\n",
    "        # Grad-CAM을 적용하기 위해 이미지 차원을 확장합니다 (배치 크기 1).\n",
    "        input_tensor = original_img_tensor.unsqueeze(0)\n",
    "        \n",
    "        # 모델 예측 수행\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            probabilities = F.softmax(output, dim=1) # 소프트맥스로 확률 변환\n",
    "            predicted_prob, predicted_label = torch.max(probabilities, 1) # 가장 높은 확률과 해당 라벨\n",
    "        \n",
    "        # Grad-CAM 인스턴스에 적용할 타겟을 지정합니다. 여기서는 라벨 4에 대한 CAM을 계산합니다.\n",
    "        # 실제 예측된 라벨에 대한 CAM을 보고 싶다면 targets = [ClassifierOutputTarget(predicted_label.item())] 로 변경\n",
    "        targets = [ClassifierOutputTarget(12)] \n",
    "        \n",
    "        # Grad-CAM을 계산합니다.\n",
    "        grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "        \n",
    "        # 결과를 이미지에 덧입히기 위해 CAM 값을 첫 번째 차원을 제거합니다.\n",
    "        grayscale_cam = grayscale_cam[0, :]\n",
    "\n",
    "        # 원본 이미지 텐서를 역정규화하고 NumPy 배열로 변환\n",
    "        denormalized_rgb_img = denormalize_image(original_img_tensor.cpu())\n",
    "        \n",
    "        # CAM 히트맵을 역정규화된 원본 이미지에 덧씌웁니다.\n",
    "        visualization = show_cam_on_image(denormalized_rgb_img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "        # 결과 시각화\n",
    "        plt.figure(figsize=(8, 4)) # 이미지 크기 조정\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(denormalized_rgb_img)\n",
    "        plt.title(f\"Original Image (Actual: {actual_label})\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(visualization)\n",
    "        plt.title(f\"Grad-CAM (Predicted: {predicted_label.item()}, Prob: {predicted_prob.item():.2f})\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.suptitle(f\"Image {k+1}/{len(label_4_images_info)} (Dataset Index: {original_idx})\")\n",
    "        plt.show()\n",
    "        \n",
    "        # 3장만 우선 보고 싶다면, 여기서 break\n",
    "        if k >= 100: \n",
    "           break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cdc6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 라벨 4인 첫 번째 이미지와 그 인덱스를 찾습니다.\n",
    "# label_4_image = None\n",
    "# label_4_index = -1\n",
    "# for i, (img, label) in enumerate(test_dataset):\n",
    "#     if label == 7:\n",
    "#         label_4_image = img\n",
    "#         label_4_index = i\n",
    "#         break\n",
    "\n",
    "# if label_4_image is None:\n",
    "#     print(\"라벨이 4인 이미지를 찾을 수 없습니다.\")\n",
    "# else:\n",
    "#     print(f\"라벨 4인 이미지 발견! 인덱스: {label_4_index}\")\n",
    "    \n",
    "#     # Grad-CAM을 적용하기 위해 이미지 차원을 확장합니다 (배치 크기 1).\n",
    "#     input_tensor = label_4_image.unsqueeze(0)\n",
    "    \n",
    "#     # Grad-CAM 인스턴스에 적용할 타겟을 지정합니다. 여기서는 라벨 4에 대한 CAM을 계산합니다.\n",
    "#     targets = [ClassifierOutputTarget(4)]\n",
    "    \n",
    "#     # Grad-CAM을 계산합니다.\n",
    "#     grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "\n",
    "#     # 결과를 이미지에 덧입히기 위해 CAM 값을 첫 번째 차원을 제거합니다.\n",
    "#     grayscale_cam = grayscale_cam[0, :]\n",
    "\n",
    "#     # 원본 이미지를 시각화를 위해 NumPy 배열로 변환합니다.\n",
    "#     rgb_img = np.float32(label_4_image) / 255\n",
    "#     rgb_img = np.transpose(rgb_img, (1,2,0))\n",
    "    \n",
    "#     # CAM 히트맵을 원본 이미지에 덧씌웁니다.\n",
    "#     visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "#     # 결과 시각화\n",
    "#     plt.imshow(visualization)\n",
    "#     plt.title(f\"Grad-CAM Visualization for Label 4\")\n",
    "#     plt.axis('off')\n",
    "#     plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-aug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
