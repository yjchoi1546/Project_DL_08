{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3641558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM, AblationCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, scale_cam_image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "import torchvision.models as models\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F # 소프트맥스 활성화를 위해 추가\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2ee78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = models.convnext_base(pretrained=False)\n",
    "print(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e2b108",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.load(\"model/best_convnext_model.pth\", map_location=torch.device('cpu'))\n",
    "model = models.convnext_base(pretrained=False)\n",
    "model.classifier[2] = nn.Linear(in_features=1024, out_features=13, bias=True)\n",
    "model.load_state_dict(weights)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4208a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_datasets = ImageFolder(root='data/Dataset_project4')\n",
    "class_names = full_datasets.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876550bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리: 모델을 학습할 때 사용한 전처리(특히 normalize)와 동일해야 함\n",
    "transforms_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "# 시각화를 위한 원본 이미지(0..1) 변환 (show_cam_on_image은 float 이미지 0..1 필요)\n",
    "to_rgb_float = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()  # 0..1 float\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575dc7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 데이터 크기와 target 저장 \n",
    "total_size = len(full_datasets)\n",
    "targets = full_datasets.targets\n",
    "\n",
    "train_indices, test_indices = train_test_split(\n",
    "    np.arange(total_size),\n",
    "    test_size=0.2,\n",
    "    stratify=targets,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(full_datasets, train_indices)\n",
    "test_dataset = torch.utils.data.Subset(full_datasets, test_indices)\n",
    "\n",
    "print(\"\\n데이터셋 분할 완료.\")\n",
    "print(f\"총 데이터 수: {total_size}\")\n",
    "print(f\"학습용 데이터 수: {len(train_dataset)}\")\n",
    "print(f\"검증용 데이터 수: {len(test_dataset)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb42a537",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.dataset.transform = transforms_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2db6dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = test_dataset[0]\n",
    "\n",
    "print(img.shape)\n",
    "print(label)\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767b2dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layer = model.features[-1][0] # block안에 들어가서 conv2d만 추출\n",
    "target_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08c7a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = GradCAM(model=model, target_layers=[target_layer])\n",
    "cam.batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7cfc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet 표준 정규화 값 (모델 학습 시 사용한 값과 일치해야 함)\n",
    "# 만약 다른 값으로 정규화했다면 이 값을 변경해야 합니다.\n",
    "NORM_MEAN = [0.485, 0.456, 0.406]\n",
    "NORM_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "def denormalize_image(tensor_image, mean=NORM_MEAN, std=NORM_STD):\n",
    "    \"\"\"\n",
    "    정규화된 이미지 텐서를 역정규화하여 0-1 범위의 NumPy 배열로 변환합니다.\n",
    "    \"\"\"\n",
    "    for t, m, s in zip(tensor_image, mean, std):\n",
    "        t.mul_(s).add_(m) # t = t * s + m\n",
    "    \n",
    "    # 텐서를 NumPy 배열로 변환하고 채널 순서를 (H, W, C)로 변경\n",
    "    np_image = tensor_image.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    # 픽셀 값을 0-1 범위로 클리핑하여 유효한 이미지 범위 유지\n",
    "    np_image = np.clip(np_image, 0, 1)\n",
    "    \n",
    "    return np_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe79e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨 4인 이미지를 저장할 리스트\n",
    "label_4_images_info = []\n",
    "count = 0\n",
    "\n",
    "# test_dataset에서 라벨이 4인 이미지 최대 100개를 찾습니다.\n",
    "for i, (img, label) in enumerate(test_dataset):\n",
    "    if label == 4:\n",
    "        label_4_images_info.append((img, label, i)) # (이미지 텐서, 실제 라벨, 원본 인덱스)\n",
    "        count += 1\n",
    "        if count >= 20:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb39229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 평가 모드로 설정\n",
    "model.eval()\n",
    "\n",
    "if not label_4_images_info:\n",
    "    print(\"라벨이 4인 이미지를 찾을 수 없습니다.\")\n",
    "else:\n",
    "    print(f\"라벨이 4인 이미지 {len(label_4_images_info)}개를 찾았습니다. 시각화를 시작합니다.\")\n",
    "\n",
    "    # 각 이미지에 대해 Grad-CAM과 예측을 시각화\n",
    "    for k, (original_img_tensor, actual_label, original_idx) in enumerate(label_4_images_info):\n",
    "        # Grad-CAM을 적용하기 위해 이미지 차원을 확장합니다 (배치 크기 1).\n",
    "        input_tensor = original_img_tensor.unsqueeze(0)\n",
    "        \n",
    "        # 모델 예측 수행\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            probabilities = F.softmax(output, dim=1) # 소프트맥스로 확률 변환\n",
    "            predicted_prob, predicted_label = torch.max(probabilities, 1) # 가장 높은 확률과 해당 라벨\n",
    "        \n",
    "        # Grad-CAM 인스턴스에 적용할 타겟을 지정합니다. 여기서는 라벨 4에 대한 CAM을 계산합니다.\n",
    "        # 실제 예측된 라벨에 대한 CAM을 보고 싶다면 targets = [ClassifierOutputTarget(predicted_label.item())] 로 변경\n",
    "        targets = [ClassifierOutputTarget(4)] \n",
    "        \n",
    "        # Grad-CAM을 계산합니다.\n",
    "        grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "        \n",
    "        # 결과를 이미지에 덧입히기 위해 CAM 값을 첫 번째 차원을 제거합니다.\n",
    "        grayscale_cam = grayscale_cam[0, :]\n",
    "\n",
    "        # 원본 이미지 텐서를 역정규화하고 NumPy 배열로 변환\n",
    "        denormalized_rgb_img = denormalize_image(original_img_tensor.cpu())\n",
    "        \n",
    "        # CAM 히트맵을 역정규화된 원본 이미지에 덧씌웁니다.\n",
    "        visualization = show_cam_on_image(denormalized_rgb_img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "        # 결과 시각화\n",
    "        plt.figure(figsize=(8, 4)) # 이미지 크기 조정\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(denormalized_rgb_img)\n",
    "        plt.title(f\"Original Image (Actual: {actual_label})\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(visualization)\n",
    "        plt.title(f\"Grad-CAM (Predicted: {predicted_label.item()}, Prob: {predicted_prob.item():.2f})\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.suptitle(f\"Image {k+1}/{len(label_4_images_info)} (Dataset Index: {original_idx})\")\n",
    "        plt.show()\n",
    "        \n",
    "        # n장만 우선 보고 싶다면, 여기서 break\n",
    "        if k >= 20: \n",
    "           break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364d1888",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-aug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
