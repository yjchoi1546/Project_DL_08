{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c5a3f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, csv, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import Adam\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d341f544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# 로컬용\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# # 서버용\n",
    "# DEVICE = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE, torch.cuda.get_device_name(0) if DEVICE.type==\"cuda\" else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "959e1eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.6\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f8ff95",
   "metadata": {},
   "source": [
    "# 경로설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e78f79ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 이미지: 69898\n",
      "label\n",
      "plastic_pp            9118\n",
      "plastic_ps            9112\n",
      "pet_clear             9104\n",
      "pet_colored           7707\n",
      "metal_can_steel       7016\n",
      "plastic_pe            5968\n",
      "metal_can_aluminum    4966\n",
      "paper                 4963\n",
      "styrofoam             3501\n",
      "glass_clear           2141\n",
      "vinyl                 2103\n",
      "glass_brown           2101\n",
      "glass_green           2098\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# # 서버PC 버전\n",
    "# ROOT = Path(\"/home/wanted-1/PotenupWorkspace/aug-project4/data/Dataset_project4\")   # <- 본인 데이터 경로\n",
    "\n",
    "# 로컬\n",
    "ROOT = Path(\"data/Dataset_project4\")\n",
    "CLASS_NAMES = [\n",
    "    \"metal_can_steel\",\"metal_can_aluminum\",\"paper\",\n",
    "    \"pet_clear\",\"pet_colored\",\n",
    "    \"plastic_pe\",\"plastic_pp\",\"plastic_ps\",\n",
    "    \"styrofoam\",\"vinyl\",\n",
    "    \"glass_brown\",\"glass_green\",\"glass_clear\"\n",
    "]\n",
    "CLASS_TO_ID = {c:i for i,c in enumerate(CLASS_NAMES)}\n",
    "\n",
    "IMG_EXTS = {\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\"}\n",
    "\n",
    "def infer_class(p: Path):\n",
    "    s = str(p)\n",
    "    if \"철캔\" in s: return \"metal_can_steel\"\n",
    "    if \"알루미늄캔\" in s: return \"metal_can_aluminum\"\n",
    "    if \"종이\" in s: return \"paper\"\n",
    "    if \"무색\" in s: return \"pet_clear\"\n",
    "    if \"유색\" in s: return \"pet_colored\"\n",
    "    if \"PE\" in s: return \"plastic_pe\"\n",
    "    if \"PP\" in s: return \"plastic_pp\"\n",
    "    if \"PS\" in s: return \"plastic_ps\"\n",
    "    if \"스티로폼\" in s: return \"styrofoam\"\n",
    "    if \"비닐\" in s: return \"vinyl\"\n",
    "    if \"갈색\" in s: return \"glass_brown\"\n",
    "    if \"녹색\" in s: return \"glass_green\"\n",
    "    if \"투명\" in s: return \"glass_clear\"\n",
    "    return None\n",
    "\n",
    "def build_df(root: Path):\n",
    "    paths, labels = [], []\n",
    "    \n",
    "    # 클래스 폴더 이름과 실제 클래스 이름을 매핑\n",
    "    # '유리병_갈색' -> 'glass_brown', '유리병_녹색' -> 'glass_green' 등\n",
    "    folder_to_class = {\n",
    "        \"금속캔알루미늄캔\": \"metal_can_aluminum\",\n",
    "        \"금속캔철캔\": \"metal_can_steel\",\n",
    "        \"비닐\": \"vinyl\",\n",
    "        \"스티로폼\": \"styrofoam\",\n",
    "        \"유리병갈색\": \"glass_brown\",\n",
    "        \"유리병녹색\": \"glass_green\",\n",
    "        \"유리병투명\": \"glass_clear\",\n",
    "        \"종이\": \"paper\",\n",
    "        \"페트병무색단일\": \"pet_clear\",\n",
    "        \"페트병유색단일\": \"pet_colored\",\n",
    "        \"플라스틱PE\": \"plastic_pe\",\n",
    "        \"플라스틱PP\": \"plastic_pp\",\n",
    "        \"플라스틱PS\": \"plastic_ps\"\n",
    "    }\n",
    "\n",
    "    # 루트 폴더의 각 하위 폴더를 탐색\n",
    "    for folder_path in root.iterdir():\n",
    "        if folder_path.is_dir() and folder_path.name in folder_to_class:\n",
    "            class_name = folder_to_class[folder_path.name]\n",
    "            \n",
    "            # 해당 클래스 폴더 내의 모든 이미지 파일 탐색\n",
    "            for img_path in folder_path.rglob(\"*\"):\n",
    "                if img_path.suffix.lower() in IMG_EXTS:\n",
    "                    paths.append(str(img_path))\n",
    "                    labels.append(class_name)\n",
    "\n",
    "    df = pd.DataFrame({\"path\": paths, \"label\": labels})\n",
    "    return df\n",
    "\n",
    "df = build_df(ROOT)\n",
    "print(\"총 이미지:\", len(df))\n",
    "print(df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5873b9",
   "metadata": {},
   "source": [
    "# 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26ba2c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터셋 크기: 55918\n",
      "테스트 데이터셋 크기: 13980\n",
      "\n",
      "학습 데이터셋 클래스별 분포:\n",
      "label\n",
      "plastic_pp            7294\n",
      "plastic_ps            7290\n",
      "pet_clear             7283\n",
      "pet_colored           6166\n",
      "metal_can_steel       5613\n",
      "plastic_pe            4774\n",
      "metal_can_aluminum    3973\n",
      "paper                 3970\n",
      "styrofoam             2801\n",
      "glass_clear           1713\n",
      "vinyl                 1682\n",
      "glass_brown           1681\n",
      "glass_green           1678\n",
      "Name: count, dtype: int64\n",
      "\n",
      "테스트 데이터셋 클래스별 분포:\n",
      "label\n",
      "plastic_pp            1824\n",
      "plastic_ps            1822\n",
      "pet_clear             1821\n",
      "pet_colored           1541\n",
      "metal_can_steel       1403\n",
      "plastic_pe            1194\n",
      "metal_can_aluminum     993\n",
      "paper                  993\n",
      "styrofoam              700\n",
      "glass_clear            428\n",
      "vinyl                  421\n",
      "glass_green            420\n",
      "glass_brown            420\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "\n",
    "print(\"학습 데이터셋 크기:\", len(train_df))\n",
    "print(\"테스트 데이터셋 크기:\", len(test_df))\n",
    "\n",
    "print(\"\\n학습 데이터셋 클래스별 분포:\")\n",
    "print(train_df['label'].value_counts())\n",
    "\n",
    "print(\"\\n테스트 데이터셋 클래스별 분포:\")\n",
    "print(test_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d608512d",
   "metadata": {},
   "source": [
    "# 클래스 불균형 문제 해결: WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62150943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "클래스별 샘플 수:\n",
      " label\n",
      "plastic_pp            7294\n",
      "plastic_ps            7290\n",
      "pet_clear             7283\n",
      "pet_colored           6166\n",
      "metal_can_steel       5613\n",
      "plastic_pe            4774\n",
      "metal_can_aluminum    3973\n",
      "paper                 3970\n",
      "styrofoam             2801\n",
      "glass_clear           1713\n",
      "vinyl                 1682\n",
      "glass_brown           1681\n",
      "glass_green           1678\n",
      "Name: count, dtype: int64\n",
      "\n",
      "클래스별 가중치:\n",
      " {'plastic_pp': 7.6663010693720866, 'plastic_ps': 7.670507544581619, 'pet_clear': 7.677879994507758, 'pet_colored': 9.068764190723321, 'metal_can_steel': 9.962230536255122, 'plastic_pe': 11.713028906577293, 'metal_can_aluminum': 14.074502894538133, 'paper': 14.085138539042822, 'styrofoam': 19.963584434130667, 'glass_clear': 32.64331582019848, 'vinyl': 33.244946492271104, 'glass_brown': 33.264723378941106, 'glass_green': 33.32419547079857}\n",
      "\n",
      "WeightedRandomSampler가 성공적으로 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 클래스별 샘플 수 계산\n",
    "class_counts = train_df['label'].value_counts()\n",
    "print(\"\\n클래스별 샘플 수:\\n\", class_counts)\n",
    "\n",
    "# 각 클래스에 대한 가중치 계산 (총 샘플 수 / 해당 클래스 샘플 수)\n",
    "num_samples = len(train_df)\n",
    "class_weights = {class_name: num_samples / count for class_name, count in class_counts.items()}\n",
    "print('\\n클래스별 가중치:\\n', class_weights)\n",
    "\n",
    "# 학습 데이터프레임의 각 샘플에 대한 가중치 할당\n",
    "train_weights = train_df['label'].apply(lambda x: class_weights[x])\n",
    "\n",
    "# weightedRandomSampler 생성\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=train_weights.values,\n",
    "    num_samples=len(train_weights),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "print(\"\\nWeightedRandomSampler가 성공적으로 생성되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3f3bf8",
   "metadata": {},
   "source": [
    "# 파이토치 Dataset & DataLoader 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c5e7825",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, class_to_id, transform=None):\n",
    "        self.df = df\n",
    "        self.class_to_id = class_to_id\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = row['path']\n",
    "        label_name = row['label']\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label_id = self.class_to_id[label_name]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4721b6",
   "metadata": {},
   "source": [
    "# 데이터 증강 및 전처리 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7e65364",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 512\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.2),\n",
    "    # 무작위 원근 왜곡 추가\n",
    "    transforms.RandomPerspective(distortion_scale=0.5, p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a556d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 인스턴스 생성\n",
    "train_dataset = CustomDataset(train_df, CLASS_TO_ID, train_transforms)\n",
    "test_dataset = CustomDataset(test_df, CLASS_TO_ID, test_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler, num_workers=0) # WeightedRandomSampler 적용\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0) # num_workers 매개변수는 데이터 로딩에 사용할 서브프로세스의 개수를 결정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "634f4e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1748\n",
      "437\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667cc7e6",
   "metadata": {},
   "source": [
    "# 모델 정의 및 학습 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c1fdb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model, loss, optimizer가 준비되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 사전 학습된 ResNet50 모델 로드\n",
    "\n",
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# 마지막 Fully Connected 레이어 수정\n",
    "# ResNet50의 마지막 레이어는 1000개의 클래스를 분류하도록 되어 있음\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs,len(CLASS_NAMES))\n",
    "\n",
    "# 모델을 GPU(DEVICE)로 이동\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# 손실 함수와 옵티마이저 정의\n",
    "lr = 1e-3\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "print(\"model, loss, optimizer가 준비되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407a2055",
   "metadata": {},
   "source": [
    "# 학습 루프 및 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f6e570",
   "metadata": {},
   "source": [
    "## epochs = 5 , batch size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2a44dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=5):\n",
    "    writer = SummaryWriter()\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for i, (images, labels) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            if (i + 1) % 50 == 0:\n",
    "                print(f\"[Epoch {epoch+1}/{num_epochs}, Batch {i+1}/{len(train_loader)}] Loss: {loss.item():.4f}\")\n",
    "\n",
    "        epoch_train_loss = train_loss / len(train_loader.dataset)\n",
    "        writer.add_scalar('Loss/train', epoch_train_loss, epoch)\n",
    "\n",
    "        # 모델 평가\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Eval]\"):\n",
    "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item() * images.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        epoch_test_loss = test_loss / len(test_loader.dataset)\n",
    "        \n",
    "        # --- 새로운 평가 지표 계산 및 출력 ---\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "        recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "        \n",
    "        # 상세 Classification Report 출력\n",
    "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} Performance Report ---\")\n",
    "        print(f\"Test Loss: {epoch_test_loss:.4f}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1-Score: {f1:.4f}\")\n",
    "        print(\"\\nClassification Report:\\n\", classification_report(all_labels, all_preds, target_names=CLASS_NAMES, zero_division=0))\n",
    "        print(\"--------------------------------------------------\")\n",
    "\n",
    "        # 텐서보드에 지표 기록\n",
    "        writer.add_scalar('Loss/test', epoch_test_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/test', accuracy, epoch)\n",
    "        writer.add_scalar('Precision/test', precision, epoch)\n",
    "        writer.add_scalar('Recall/test', recall, epoch)\n",
    "        writer.add_scalar('F1-Score/test', f1, epoch)\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "\n",
    "            # 더 많은 정보를 딕셔너리에 추가\n",
    "            best_classification_report = classification_report(all_labels, all_preds, target_names=CLASS_NAMES, zero_division=0)\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_accuracy': best_accuracy,\n",
    "            'best_f1_score': f1,  # F1-Score 추가\n",
    "            'best_classification_report': best_classification_report  # Classification Report 추가\n",
    "        }, 'best_model_checkpoint.pth')\n",
    "        print(f\"새로운 최고 정확도 달성: {best_accuracy:.4f}. 상세 지표를 저장합니다.\")\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "# --- 학습 시작 ---\n",
    "if __name__ == '__main__':\n",
    "    train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=5)\n",
    "    print(\"학습이 완료되었습니다.\")\n",
    "    final_model_path = \"model/Best_ResNet50_model.pth\"\n",
    "    torch.save(model.state_dict(), final_model_path)\n",
    "    print(f\"최종 모델이 '{final_model_path}'에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ac7670",
   "metadata": {},
   "source": [
    "# 나중에 불러와서, 하이퍼파라미터 수정하고 체크포인트 부분부터 수정할 때."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6ef1e0",
   "metadata": {},
   "source": [
    "## epochs = 12, batch size =32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f86eb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "체크포인트 파일이 없습니다. 0 에포크부터 학습을 시작합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]:   0%|          | 0/1748 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# 모델 정의 (ResNet50)\n",
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(CLASS_NAMES))\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# --- 체크포인트 로드 ---\n",
    "start_epoch = 0\n",
    "best_accuracy = 0.0\n",
    "checkpoint_path = 'checkpoint/best_model_checkpoint.pth'\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(\"체크포인트를 로드하여 학습을 재개합니다.\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    best_accuracy = checkpoint['best_accuracy']\n",
    "    print(f\"이전 최고 정확도: {best_accuracy:.4f}, 이어서 시작할 에포크: {start_epoch + 1}\")\n",
    "else:\n",
    "    print(\"체크포인트 파일이 없습니다. 0 에포크부터 학습을 시작합니다.\")\n",
    "\n",
    "\n",
    "\n",
    "# --- 학습 함수 정의(이전 코드와 동일) ---\n",
    "def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs, start_epoch, best_accuracy):\n",
    "    writer = SummaryWriter()\n",
    "    \n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for i, (images, labels) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            if (i + 1) % 50 == 0:\n",
    "                print(f\"[Epoch {epoch+1}/{num_epochs}, Batch {i+1}/{len(train_loader)}] Loss: {loss.item():.4f}\")\n",
    "\n",
    "        epoch_train_loss = train_loss / len(train_loader.dataset)\n",
    "        writer.add_scalar('Loss/train', epoch_train_loss, epoch)\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Eval]\"):\n",
    "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item() * images.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        epoch_test_loss = test_loss / len(test_loader.dataset)\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "        recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "        \n",
    "        print(f\"\\n--- Epoch {epoch+1}/{num_epochs} Performance Report ---\")\n",
    "        print(f\"Test Loss: {epoch_test_loss:.4f}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1-Score: {f1:.4f}\")\n",
    "        print(\"\\nClassification Report:\\n\", classification_report(all_labels, all_preds, target_names=CLASS_NAMES, zero_division=0))\n",
    "        print(\"--------------------------------------------------\")\n",
    "\n",
    "        writer.add_scalar('Loss/test', epoch_test_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/test', accuracy, epoch)\n",
    "        writer.add_scalar('Precision/test', precision, epoch)\n",
    "        writer.add_scalar('Recall/test', recall, epoch)\n",
    "        writer.add_scalar('F1-Score/test', f1, epoch)\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            # 더 많은 정보를 딕셔너리에 추가\n",
    "            best_classification_report = classification_report(all_labels, all_preds, target_names=CLASS_NAMES, zero_division=0)\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_accuracy': best_accuracy,\n",
    "            'best_f1_score': f1,  # F1-Score 추가\n",
    "            'best_classification_report': best_classification_report  # Classification Report 추가\n",
    "        }, 'best_model_checkpoint.pth')\n",
    "        print(f\"새로운 최고 정확도 달성: {best_accuracy:.4f}. 상세 지표를 저장합니다.\")\n",
    "        \n",
    "    writer.close()\n",
    "        \n",
    "# --- 학습 실행 ---\n",
    "num_epochs_to_run = 10 # 총 학습시키고 싶은 에포크 수\n",
    "train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=num_epochs_to_run, start_epoch=start_epoch, best_accuracy=best_accuracy)\n",
    "\n",
    "print(\"학습이 완료되었습니다.\")\n",
    "# 현재 시간을 이용해 파일 이름 생성\n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "final_model_path = f\"model/Best_ResNet50_model_{timestamp}.pth\" # 타임라인별로 모델 저장\n",
    "torch.save(model.state_dict(), final_model_path) \n",
    "print(f\"최종 모델이 '{final_model_path}'에 저장되었습니다.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f94689",
   "metadata": {},
   "source": [
    "# 최적의 점수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620d5d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 체크포인트 파일 경로 설정\n",
    "checkpoint_path = 'checkpoint/best_model_checkpoint.pth'\n",
    "\n",
    "# 체크포인트 파일이 있는지 확인\n",
    "if os.path.exists(checkpoint_path):\n",
    "    # GPU 사용 여부 확인 후 체크포인트 로드\n",
    "    map_location = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    print(f\"'{checkpoint_path}' 파일을 불러옵니다.\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=map_location) # map_location은 저장된 가중치를 불러올 때 어디로 불러올지를 정해주는 역할\n",
    "\n",
    "    # 저장된 상세 정보 출력\n",
    "    print(\"=====================================================\")\n",
    "    print(\"최고 성능 기록 정보\")\n",
    "    print(\"-----------------------------------------------------\")\n",
    "    print(f\"최고 정확도 달성 에포크: {checkpoint['epoch']} 에포크\")\n",
    "    print(f\"최고 정확도: {checkpoint['best_accuracy']:.4f}\")\n",
    "    # print(f\"최고 정밀도: {checkpoint['best_precision']:.4f}\")\n",
    "    # print(f\"최고 재현율: {checkpoint['best_recall']:.4f}\")\n",
    "    # print(f\"최고 F1-Score: {checkpoint['best_f1']:.4f}\")\n",
    "    # print(\"-----------------------------------------------------\")\n",
    "    # print(\"\\n상세 Classification Report:\\n\")\n",
    "    # print(checkpoint['best_classification_report'])\n",
    "    print(\"=====================================================\")\n",
    "\n",
    "else:\n",
    "    print(f\"오류: '{checkpoint_path}' 파일이 존재하지 않습니다. 학습을 먼저 완료해주세요.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-aug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
