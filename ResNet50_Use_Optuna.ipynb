{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f83100ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, csv, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed4a00b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# --- ê¸°ë³¸ ì„¤ì • ---\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE, torch.cuda.get_device_name(0) if DEVICE.type==\"cuda\" else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17372199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- ë°ì´í„°ì…‹ ê²½ë¡œ ë° í´ë˜ìŠ¤ ì •ì˜ ---\n",
    "# ROOT = Path(\"/home/wanted-1/PotenupWorkspace/aug-project4/data/Dataset_project4\")\n",
    "ROOT = Path(\"data/Dataset_project4\")\n",
    "\n",
    "CLASS_NAMES = [\n",
    "    \"metal_can_steel\", \"metal_can_aluminum\", \"paper\",\n",
    "    \"pet_clear\", \"pet_colored\",\n",
    "    \"plastic_pe\", \"plastic_pp\", \"plastic_ps\",\n",
    "    \"styrofoam\", \"vinyl\",\n",
    "    \"glass_brown\", \"glass_green\", \"glass_clear\"\n",
    "]\n",
    "CLASS_TO_ID = {c: i for i, c in enumerate(CLASS_NAMES)}\n",
    "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}\n",
    "\n",
    "def build_df(root: Path):\n",
    "    paths, labels = [], []\n",
    "    folder_to_class = {\n",
    "        \"ê¸ˆì†ìº”ì•Œë£¨ë¯¸ëŠ„ìº”\": \"metal_can_aluminum\", \"ê¸ˆì†ìº”ì² ìº”\": \"metal_can_steel\",\n",
    "        \"ë¹„ë‹\": \"vinyl\", \"ìŠ¤í‹°ë¡œí¼\": \"styrofoam\",\n",
    "        \"ìœ ë¦¬ë³‘_ê°ˆìƒ‰\": \"glass_brown\", \"ìœ ë¦¬ë³‘_ë…¹ìƒ‰\": \"glass_green\", \"ìœ ë¦¬ë³‘_íˆ¬ëª…\": \"glass_clear\",\n",
    "        \"ì¢…ì´\": \"paper\", \"í˜íŠ¸ë³‘ë¬´ìƒ‰ë‹¨ì¼\": \"pet_clear\", \"í˜íŠ¸ë³‘ìœ ìƒ‰ë‹¨ì¼\": \"pet_colored\",\n",
    "        \"í”Œë¼ìŠ¤í‹±PE\": \"plastic_pe\", \"í”Œë¼ìŠ¤í‹±PP\": \"plastic_pp\", \"í”Œë¼ìŠ¤í‹±PS\": \"plastic_ps\"\n",
    "    }\n",
    "    for folder_path in root.iterdir():\n",
    "        if folder_path.is_dir() and folder_path.name in folder_to_class:\n",
    "            class_name = folder_to_class[folder_path.name]\n",
    "            for img_path in folder_path.rglob(\"*\"):\n",
    "                if img_path.suffix.lower() in IMG_EXTS:\n",
    "                    paths.append(str(img_path))\n",
    "                    labels.append(class_name)\n",
    "    df = pd.DataFrame({\"path\": paths, \"label\": labels})\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b525600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìµœì í™”ìš© ìƒ˜í”Œë§ëœ í•™ìŠµ ë°ì´í„°ì…‹ í¬ê¸°: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_28556\\2289011753.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=min(len(x), 100), random_state=42))\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_28556\\2289011753.py:13: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=min(len(x), 20), random_state=42))\n"
     ]
    }
   ],
   "source": [
    "# --- ë°ì´í„°ì…‹ ë¶„í•  ë° DataLoader ì„¤ì • ---\n",
    "df = build_df(ROOT)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "\n",
    "# NOTE: Optuna ì‹¤í–‰ ì‹œê°„ì„ ì¤„ì´ê¸° ìœ„í•´ ì†ŒëŸ‰ì˜ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸\n",
    "sample_train_df = (\n",
    "    train_df.groupby('label', group_keys=False)\n",
    "    .apply(lambda x: x.sample(n=min(len(x), 100), random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "sample_test_df = (\n",
    "    test_df.groupby('label', group_keys=False)\n",
    "    .apply(lambda x: x.sample(n=min(len(x), 20), random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "train_df_optuna, test_df_optuna = sample_train_df, sample_test_df\n",
    "print(f\"ìµœì í™”ìš© ìƒ˜í”Œë§ëœ í•™ìŠµ ë°ì´í„°ì…‹ í¬ê¸°: {len(train_df_optuna)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca2db465",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, class_to_id, transform=None):\n",
    "        self.df = df\n",
    "        self.class_to_id = class_to_id\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = row['path']\n",
    "        label_name = row['label']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label_id = self.class_to_id[label_name]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label_id\n",
    "\n",
    "IMG_SIZE = 512\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset_optuna = CustomDataset(train_df_optuna, CLASS_TO_ID, train_transforms)\n",
    "test_dataset_optuna = CustomDataset(test_df_optuna, CLASS_TO_ID, test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc8fc606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Optuna objective í•¨ìˆ˜ ì •ì˜ ---\n",
    "def objective(trial):\n",
    "    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì œì•ˆ\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [8, 16, 32])\n",
    "    num_epochs = trial.suggest_int('num_epochs', 5, 10)\n",
    "\n",
    "    # DataLoader ì¬ì •ì˜ (batch_size ì ìš©)\n",
    "    class_counts = train_df_optuna['label'].value_counts()\n",
    "    num_samples = len(train_df_optuna)\n",
    "    class_weights = {class_name: num_samples / count for class_name, count in class_counts.items()}\n",
    "    train_weights = train_df_optuna['label'].apply(lambda x: class_weights[x])\n",
    "    sampler = WeightedRandomSampler(weights=train_weights.values, num_samples=len(train_weights), replacement=True)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset_optuna, batch_size=batch_size, sampler=sampler, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset_optuna, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    # ëª¨ë¸, ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì •ì˜ (í•˜ì´í¼íŒŒë¼ë¯¸í„° ì ìš©)\n",
    "    model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, len(CLASS_NAMES))\n",
    "    model = model.to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        # í•™ìŠµ ë° í‰ê°€ ë£¨í”„ (ê°„ì†Œí™”)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # ëª¨ë¸ í‰ê°€ (ë§¤ ì—í¬í¬ë§ˆë‹¤ í‰ê°€í•  í•„ìš”ëŠ” ì—†ì§€ë§Œ, ê°„ë‹¨í•œ ì˜ˆì‹œë¥¼ ìœ„í•´ í¬í•¨)\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a99866e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-25 15:16:52,615] A new study created in memory with name: no-name-b349bb69-bb12-4f12-a10a-77e435a049b7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "081b19a6bfca4bab8e11655b066a5a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_28556\\2879915705.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-25 15:30:03,497] Trial 0 finished with value: 0.75 and parameters: {'learning_rate': 0.0001023182681290303, 'batch_size': 16, 'num_epochs': 7}. Best is trial 0 with value: 0.75.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_28556\\2879915705.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-25 15:36:41,336] Trial 1 finished with value: 0.695 and parameters: {'learning_rate': 0.0003600737092628432, 'batch_size': 8, 'num_epochs': 10}. Best is trial 0 with value: 0.75.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_28556\\2879915705.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-08-25 15:38:05,248] Trial 2 failed with parameters: {'learning_rate': 3.8704561107071174e-05, 'batch_size': 8, 'num_epochs': 5} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\project_aug\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_28556\\2879915705.py\", line 33, in objective\n",
      "    loss.backward()\n",
      "  File \"c:\\project_aug\\.venv\\lib\\site-packages\\torch\\_tensor.py\", line 647, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"c:\\project_aug\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"c:\\project_aug\\.venv\\lib\\site-packages\\torch\\autograd\\graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "[W 2025-08-25 15:38:05,289] Trial 2 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# --- Optuna ìµœì í™” ì‹¤í–‰ ---\u001b[39;00m\n\u001b[0;32m      2\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m===========================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ† ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ë° ìµœê³  ì„±ëŠ¥\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\project_aug\\.venv\\lib\\site-packages\\optuna\\study\\study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    397\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 490\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\project_aug\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\project_aug\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial_id \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\project_aug\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:258\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    254\u001b[0m     updated_state \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    257\u001b[0m ):\n\u001b[1;32m--> 258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial\u001b[38;5;241m.\u001b[39m_trial_id\n",
      "File \u001b[1;32mc:\\project_aug\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 201\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[7], line 33\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[0;32m     32\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m---> 33\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# ëª¨ë¸ í‰ê°€ (ë§¤ ì—í¬í¬ë§ˆë‹¤ í‰ê°€í•  í•„ìš”ëŠ” ì—†ì§€ë§Œ, ê°„ë‹¨í•œ ì˜ˆì‹œë¥¼ ìœ„í•´ í¬í•¨)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\project_aug\\.venv\\lib\\site-packages\\torch\\_tensor.py:647\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    639\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    640\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    645\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    646\u001b[0m     )\n\u001b[1;32m--> 647\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\project_aug\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\project_aug\\.venv\\lib\\site-packages\\torch\\autograd\\graph.py:829\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    827\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    830\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    831\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    833\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- Optuna ìµœì í™” ì‹¤í–‰ ---\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(\"\\n===========================================\")\n",
    "print(\"ğŸ† ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ë° ìµœê³  ì„±ëŠ¥\")\n",
    "print(\"-------------------------------------------\")\n",
    "print(f\"ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°: {study.best_params}\")\n",
    "print(f\"ìµœê³  ì •í™•ë„: {study.best_value:.4f}\")\n",
    "print(\"===========================================\")\n",
    "\n",
    "# --- ìµœì¢… ëª¨ë¸ í•™ìŠµ (ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì‚¬ìš©) ---\n",
    "print(f\"\\nìµœì ì˜ ê°’ìœ¼ë¡œ ì „ì²´ ë°ì´í„°ì…‹ì— ëŒ€í•œ ìµœì¢… ëª¨ë¸ í•™ìŠµ ì‹œì‘\")\n",
    "\n",
    "# ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°’ ì¶”ì¶œ\n",
    "best_lr = study.best_params['learning_rate']\n",
    "best_bs = study.best_params['batch_size']\n",
    "best_epochs = study.best_params['num_epochs']\n",
    "\n",
    "# ì „ì²´ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ train_df, test_df ì¬ì •ì˜\n",
    "df_full = build_df(ROOT)\n",
    "train_df_full, test_df_full = train_test_split(df_full, test_size=0.2, random_state=42, stratify=df_full['label'])\n",
    "\n",
    "# DataLoader ì¬êµ¬ì„± (ìµœì ì˜ batch_size ì ìš©)\n",
    "train_dataset_full = CustomDataset(train_df_full, CLASS_TO_ID, train_transforms)\n",
    "test_dataset_full = CustomDataset(test_df_full, CLASS_TO_ID, test_transforms)\n",
    "class_counts_full = train_df_full['label'].value_counts()\n",
    "num_samples_full = len(train_df_full)\n",
    "class_weights_full = {class_name: num_samples_full / count for class_name, count in class_counts_full.items()}\n",
    "train_weights_full = train_df_full['label'].apply(lambda x: class_weights_full[x])\n",
    "final_sampler = WeightedRandomSampler(weights=train_weights_full.values, num_samples=len(train_weights_full), replacement=True)\n",
    "\n",
    "final_train_loader = DataLoader(train_dataset_full, batch_size=best_bs, sampler=final_sampler, num_workers=0)\n",
    "final_test_loader = DataLoader(test_dataset_full, batch_size=best_bs, shuffle=False, num_workers=0)\n",
    "\n",
    "# ìµœì¢… ëª¨ë¸ ë° ì˜µí‹°ë§ˆì´ì € ì •ì˜ (ìµœì ì˜ learning_rate ì ìš©)\n",
    "final_model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "num_ftrs_final = final_model.fc.in_features\n",
    "final_model.fc = nn.Linear(num_ftrs_final, len(CLASS_NAMES))\n",
    "final_model = final_model.to(DEVICE)\n",
    "final_optimizer = optim.Adam(final_model.parameters(), lr=best_lr)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad05b5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì¢… í•™ìŠµ ë£¨í”„\n",
    "for epoch in range(best_epochs):\n",
    "    final_model.train()\n",
    "    for images, labels in tqdm(final_train_loader, desc=f\"Final Training Epoch {epoch+1}/{best_epochs}\"):\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        final_optimizer.zero_grad()\n",
    "        outputs = final_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        final_optimizer.step()\n",
    "    \n",
    "    # ìµœì¢… ëª¨ë¸ í‰ê°€ ë° ì¶œë ¥ (ì˜µì…˜)\n",
    "    final_model.eval()\n",
    "    all_preds_final = []\n",
    "    all_labels_final = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in final_test_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = final_model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds_final.extend(preds.cpu().numpy())\n",
    "            all_labels_final.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy_final = accuracy_score(all_labels_final, all_preds_final)\n",
    "    print(f\"\\nFinal Epoch {epoch+1}/{best_epochs} Test Accuracy: {accuracy_final:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6504979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì¢… ëª¨ë¸ ì €ì¥\n",
    "final_model_path = \"model/Best_ResNet50_Use_Optuna_model.pth\"\n",
    "if not os.path.exists('model'):\n",
    "    os.makedirs('model')\n",
    "torch.save(final_model.state_dict(), final_model_path)\n",
    "print(f\"\\nìµœì¢… ëª¨ë¸ì´ '{final_model_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-aug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
